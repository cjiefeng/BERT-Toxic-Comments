{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNLPVy3LY1+jQqPBVp9u0g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bce6711bfaf848bc84d1c53191baa254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e578b4723bde405ba64bbe5ad1a94d61",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_05fd046e6763445ea7594ad5c7bbaa05",
              "IPY_MODEL_802a4376b9664f13b729e6db7a342503"
            ]
          }
        },
        "e578b4723bde405ba64bbe5ad1a94d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05fd046e6763445ea7594ad5c7bbaa05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f66eef46a6134608af3d3cd25638c90a",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4a0e77d2d8c49e1a006785a5e62c93e"
          }
        },
        "802a4376b9664f13b729e6db7a342503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9982b22ff06b48d2b41d0a33846fc529",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 918kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae0c7c655a784acc844d74f1aa8ba179"
          }
        },
        "f66eef46a6134608af3d3cd25638c90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4a0e77d2d8c49e1a006785a5e62c93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9982b22ff06b48d2b41d0a33846fc529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae0c7c655a784acc844d74f1aa8ba179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cc05ccdce0e4cffab0f252aabd6c0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d262002c621b4b67807885aaf2ac7ac2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d93ae16b1f464d6b98bcea9dfd20e848",
              "IPY_MODEL_ea0f755cf6a54d8898799f65174e8bc0"
            ]
          }
        },
        "d262002c621b4b67807885aaf2ac7ac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d93ae16b1f464d6b98bcea9dfd20e848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a61ba32ccfb6461a9b9a6f8ca725df38",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_191ae453cde14352926a310d9b0a4025"
          }
        },
        "ea0f755cf6a54d8898799f65174e8bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71a8c063191a4f87acd68eb4dc88d011",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 15.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31a3eb14ecf5491a83cdbc680b9b3ee2"
          }
        },
        "a61ba32ccfb6461a9b9a6f8ca725df38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "191ae453cde14352926a310d9b0a4025": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71a8c063191a4f87acd68eb4dc88d011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31a3eb14ecf5491a83cdbc680b9b3ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ac5dc95cfce4fe2a5d17502db855b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6b38dd65b9d64f8e9b360fbd2ea32bea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b1a652e4e123496bbee50ae044d3dec2",
              "IPY_MODEL_5d4c9411705b44e190cca0b52633026e"
            ]
          }
        },
        "6b38dd65b9d64f8e9b360fbd2ea32bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b1a652e4e123496bbee50ae044d3dec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_876ea7a6cc3342bba48be49a7ed1896e",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88b314f65b5942b5975e712ac8cc840d"
          }
        },
        "5d4c9411705b44e190cca0b52633026e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ed0fbd3f88d4eb18f3ac289f871af6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:14&lt;00:00, 30.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d23889eeada418ba9aba084fb3c9d91"
          }
        },
        "876ea7a6cc3342bba48be49a7ed1896e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88b314f65b5942b5975e712ac8cc840d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ed0fbd3f88d4eb18f3ac289f871af6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d23889eeada418ba9aba084fb3c9d91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cjiefeng/BERT-Toxic-Comments/blob/master/Toxic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiWZnmg7a5pj",
        "colab_type": "code",
        "outputId": "b7ea09bd-afff-4d4b-cc8e-a08ff1145cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# verify GPU availability\n",
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77ge7zvJbD2G",
        "colab_type": "code",
        "outputId": "66494d6c-b010-4348-8e90-ce5616e6a06f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "# install\n",
        "!pip install transformers\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "import math\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm, trange\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 11.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 4.2MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 6.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 4.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 5.7MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 6.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 29.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 39.0MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 45.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 47.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 49.7MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 52.4MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 53.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 54.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 55.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 55.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 55.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 55.9MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 55.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 55.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 55.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 55.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 55.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 55.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 55.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 50.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=f00a68b896798326c8b96a8e53773aa3d5a5fabc171811f81b96ea22247f2be4\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dk69ccrbHgi",
        "colab_type": "code",
        "outputId": "8138f5ab-6c03-43b1-82df-d84a5b03ebcd",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Upload the train file from your local drive\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9c207fcc-3357-44ea-b243-c0d1a25bfcfb\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9c207fcc-3357-44ea-b243-c0d1a25bfcfb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train.csv to train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t64QTdBYpl_D",
        "colab_type": "code",
        "outputId": "c71d7956-b071-400b-f744-626a7f0781f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "import io\n",
        "\n",
        "# df = pd.read_csv(io.BytesIO(uploaded['train.csv']))\n",
        "df = pd.read_csv('train.csv')\n",
        "# df['id']\n",
        "# df['comment_text']\n",
        "# df['toxic'].value_counts()\n",
        "# df['severe_toxic'].value_counts()\n",
        "# df['obscene'].value_counts()\n",
        "# df['threat'].value_counts()\n",
        "# df['insult'].value_counts()\n",
        "# df['identity_hate'].value_counts()\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df['comment_text'].shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df['comment_text'].sample(10)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 159,571\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135639    Doing the references as you have means the cor...\n",
              "67738     Apparently you are not very clever as you thin...\n",
              "140683    Well that Dixon doesn't even have a page to my...\n",
              "129849    \"\\n\\nSpite\\nUser:Dennis Brown, you accused me ...\n",
              "19248     OK thus I start the poll with (I got the permi...\n",
              "118772    stockley & wakelin article \\nhi\\nRegarding del...\n",
              "85224     Do you have something against WWII generals?  ...\n",
              "8510      \"\\n\\nI'm glad that you removed the statement \"...\n",
              "10092     dont mind this weapon giy he shall not be here...\n",
              "125602    i want to appeal because this block is invalid...\n",
              "Name: comment_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AC0YskdNkCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df['comment_text'].values\n",
        "labels = df['toxic'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT-Sa73lOBhL",
        "colab_type": "code",
        "outputId": "5843d880-8970-4aef-c71e-3277c97e21d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "bce6711bfaf848bc84d1c53191baa254",
            "e578b4723bde405ba64bbe5ad1a94d61",
            "05fd046e6763445ea7594ad5c7bbaa05",
            "802a4376b9664f13b729e6db7a342503",
            "f66eef46a6134608af3d3cd25638c90a",
            "a4a0e77d2d8c49e1a006785a5e62c93e",
            "9982b22ff06b48d2b41d0a33846fc529",
            "ae0c7c655a784acc844d74f1aa8ba179"
          ]
        }
      },
      "source": [
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = ppb.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bce6711bfaf848bc84d1c53191baa254",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSDVIeTxOMyC",
        "colab_type": "code",
        "outputId": "b46a0505-5252-4b9f-9b37-d0ba9b26be31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Explanation\n",
            "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
            "Tokenized:  ['explanation', 'why', 'the', 'edit', '##s', 'made', 'under', 'my', 'user', '##name', 'hardcore', 'metallic', '##a', 'fan', 'were', 'reverted', '?', 'they', 'weren', \"'\", 't', 'van', '##dal', '##isms', ',', 'just', 'closure', 'on', 'some', 'gas', 'after', 'i', 'voted', 'at', 'new', 'york', 'dolls', 'fa', '##c', '.', 'and', 'please', 'don', \"'\", 't', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'i', \"'\", 'm', 'retired', 'now', '.', '89', '.', '205', '.', '38', '.', '27']\n",
            "Token IDs:  [7526, 2339, 1996, 10086, 2015, 2081, 2104, 2026, 5310, 18442, 13076, 12392, 2050, 5470, 2020, 16407, 1029, 2027, 4694, 1005, 1056, 3158, 9305, 22556, 1010, 2074, 8503, 2006, 2070, 3806, 2044, 1045, 5444, 2012, 2047, 2259, 14421, 6904, 2278, 1012, 1998, 3531, 2123, 1005, 1056, 6366, 1996, 23561, 2013, 1996, 2831, 3931, 2144, 1045, 1005, 1049, 3394, 2085, 1012, 6486, 1012, 16327, 1012, 4229, 1012, 2676]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4CiJlDwOYSt",
        "colab_type": "code",
        "outputId": "0296253b-7491-423b-ec5b-3423242780b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Explanation\n",
            "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
            "Token IDs: [101, 7526, 2339, 1996, 10086, 2015, 2081, 2104, 2026, 5310, 18442, 13076, 12392, 2050, 5470, 2020, 16407, 1029, 2027, 4694, 1005, 1056, 3158, 9305, 22556, 1010, 2074, 8503, 2006, 2070, 3806, 2044, 1045, 5444, 2012, 2047, 2259, 14421, 6904, 2278, 1012, 1998, 3531, 2123, 1005, 1056, 6366, 1996, 23561, 2013, 1996, 2831, 3931, 2144, 1045, 1005, 1049, 3394, 2085, 1012, 6486, 1012, 16327, 1012, 4229, 1012, 2676, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrFoWMtNOc4E",
        "colab_type": "code",
        "outputId": "e8651e3f-9f6f-4252-c4e2-55a877946ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5SOzsGXP_B-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iTZK2ZNn0XJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_1 = df['toxic']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKhfFUTuQIDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, label_1, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, label_1,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpTh8smwQR14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.from_numpy(np.asarray(train_labels))\n",
        "validation_labels = torch.from_numpy(np.asarray(validation_labels))\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82Jfm1N_R_B9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a batch size for training. \n",
        "batch_size = 32\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader \n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imtNR6nRQ14H",
        "colab_type": "code",
        "outputId": "151c6335-c4d2-425e-bc92-b40c8162efb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1cc05ccdce0e4cffab0f252aabd6c0ea",
            "d262002c621b4b67807885aaf2ac7ac2",
            "d93ae16b1f464d6b98bcea9dfd20e848",
            "ea0f755cf6a54d8898799f65174e8bc0",
            "a61ba32ccfb6461a9b9a6f8ca725df38",
            "191ae453cde14352926a310d9b0a4025",
            "71a8c063191a4f87acd68eb4dc88d011",
            "31a3eb14ecf5491a83cdbc680b9b3ee2",
            "9ac5dc95cfce4fe2a5d17502db855b6c",
            "6b38dd65b9d64f8e9b360fbd2ea32bea",
            "b1a652e4e123496bbee50ae044d3dec2",
            "5d4c9411705b44e190cca0b52633026e",
            "876ea7a6cc3342bba48be49a7ed1896e",
            "88b314f65b5942b5975e712ac8cc840d",
            "8ed0fbd3f88d4eb18f3ac289f871af6a",
            "4d23889eeada418ba9aba084fb3c9d91"
          ]
        }
      },
      "source": [
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = ppb.BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cc05ccdce0e4cffab0f252aabd6c0ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ac5dc95cfce4fe2a5d17502db855b6c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKw20leGRHwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = ppb.AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldl7bxkfRo7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = ppb.get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK7YbXUWRKeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uliTykyLR9PL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSDc-TaHSJYg",
        "colab_type": "code",
        "outputId": "5c841d74-4fba-4ffa-e678-004540c22713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,488.    Elapsed: 0:00:17.\n",
            "  Batch    80  of  4,488.    Elapsed: 0:00:33.\n",
            "  Batch   120  of  4,488.    Elapsed: 0:00:49.\n",
            "  Batch   160  of  4,488.    Elapsed: 0:01:04.\n",
            "  Batch   200  of  4,488.    Elapsed: 0:01:20.\n",
            "  Batch   240  of  4,488.    Elapsed: 0:01:36.\n",
            "  Batch   280  of  4,488.    Elapsed: 0:01:52.\n",
            "  Batch   320  of  4,488.    Elapsed: 0:02:07.\n",
            "  Batch   360  of  4,488.    Elapsed: 0:02:23.\n",
            "  Batch   400  of  4,488.    Elapsed: 0:02:39.\n",
            "  Batch   440  of  4,488.    Elapsed: 0:02:54.\n",
            "  Batch   480  of  4,488.    Elapsed: 0:03:10.\n",
            "  Batch   520  of  4,488.    Elapsed: 0:03:26.\n",
            "  Batch   560  of  4,488.    Elapsed: 0:03:42.\n",
            "  Batch   600  of  4,488.    Elapsed: 0:03:57.\n",
            "  Batch   640  of  4,488.    Elapsed: 0:04:13.\n",
            "  Batch   680  of  4,488.    Elapsed: 0:04:29.\n",
            "  Batch   720  of  4,488.    Elapsed: 0:04:44.\n",
            "  Batch   760  of  4,488.    Elapsed: 0:05:00.\n",
            "  Batch   800  of  4,488.    Elapsed: 0:05:16.\n",
            "  Batch   840  of  4,488.    Elapsed: 0:05:31.\n",
            "  Batch   880  of  4,488.    Elapsed: 0:05:47.\n",
            "  Batch   920  of  4,488.    Elapsed: 0:06:03.\n",
            "  Batch   960  of  4,488.    Elapsed: 0:06:18.\n",
            "  Batch 1,000  of  4,488.    Elapsed: 0:06:34.\n",
            "  Batch 1,040  of  4,488.    Elapsed: 0:06:50.\n",
            "  Batch 1,080  of  4,488.    Elapsed: 0:07:05.\n",
            "  Batch 1,120  of  4,488.    Elapsed: 0:07:21.\n",
            "  Batch 1,160  of  4,488.    Elapsed: 0:07:37.\n",
            "  Batch 1,200  of  4,488.    Elapsed: 0:07:52.\n",
            "  Batch 1,240  of  4,488.    Elapsed: 0:08:08.\n",
            "  Batch 1,280  of  4,488.    Elapsed: 0:08:24.\n",
            "  Batch 1,320  of  4,488.    Elapsed: 0:08:40.\n",
            "  Batch 1,360  of  4,488.    Elapsed: 0:08:55.\n",
            "  Batch 1,400  of  4,488.    Elapsed: 0:09:11.\n",
            "  Batch 1,440  of  4,488.    Elapsed: 0:09:27.\n",
            "  Batch 1,480  of  4,488.    Elapsed: 0:09:42.\n",
            "  Batch 1,520  of  4,488.    Elapsed: 0:09:58.\n",
            "  Batch 1,560  of  4,488.    Elapsed: 0:10:14.\n",
            "  Batch 1,600  of  4,488.    Elapsed: 0:10:29.\n",
            "  Batch 1,640  of  4,488.    Elapsed: 0:10:45.\n",
            "  Batch 1,680  of  4,488.    Elapsed: 0:11:01.\n",
            "  Batch 1,720  of  4,488.    Elapsed: 0:11:16.\n",
            "  Batch 1,760  of  4,488.    Elapsed: 0:11:32.\n",
            "  Batch 1,800  of  4,488.    Elapsed: 0:11:48.\n",
            "  Batch 1,840  of  4,488.    Elapsed: 0:12:03.\n",
            "  Batch 1,880  of  4,488.    Elapsed: 0:12:19.\n",
            "  Batch 1,920  of  4,488.    Elapsed: 0:12:35.\n",
            "  Batch 1,960  of  4,488.    Elapsed: 0:12:50.\n",
            "  Batch 2,000  of  4,488.    Elapsed: 0:13:06.\n",
            "  Batch 2,040  of  4,488.    Elapsed: 0:13:22.\n",
            "  Batch 2,080  of  4,488.    Elapsed: 0:13:37.\n",
            "  Batch 2,120  of  4,488.    Elapsed: 0:13:53.\n",
            "  Batch 2,160  of  4,488.    Elapsed: 0:14:09.\n",
            "  Batch 2,200  of  4,488.    Elapsed: 0:14:24.\n",
            "  Batch 2,240  of  4,488.    Elapsed: 0:14:40.\n",
            "  Batch 2,280  of  4,488.    Elapsed: 0:14:56.\n",
            "  Batch 2,320  of  4,488.    Elapsed: 0:15:12.\n",
            "  Batch 2,360  of  4,488.    Elapsed: 0:15:27.\n",
            "  Batch 2,400  of  4,488.    Elapsed: 0:15:43.\n",
            "  Batch 2,440  of  4,488.    Elapsed: 0:15:59.\n",
            "  Batch 2,480  of  4,488.    Elapsed: 0:16:14.\n",
            "  Batch 2,520  of  4,488.    Elapsed: 0:16:30.\n",
            "  Batch 2,560  of  4,488.    Elapsed: 0:16:46.\n",
            "  Batch 2,600  of  4,488.    Elapsed: 0:17:01.\n",
            "  Batch 2,640  of  4,488.    Elapsed: 0:17:17.\n",
            "  Batch 2,680  of  4,488.    Elapsed: 0:17:33.\n",
            "  Batch 2,720  of  4,488.    Elapsed: 0:17:48.\n",
            "  Batch 2,760  of  4,488.    Elapsed: 0:18:04.\n",
            "  Batch 2,800  of  4,488.    Elapsed: 0:18:20.\n",
            "  Batch 2,840  of  4,488.    Elapsed: 0:18:35.\n",
            "  Batch 2,880  of  4,488.    Elapsed: 0:18:51.\n",
            "  Batch 2,920  of  4,488.    Elapsed: 0:19:07.\n",
            "  Batch 2,960  of  4,488.    Elapsed: 0:19:22.\n",
            "  Batch 3,000  of  4,488.    Elapsed: 0:19:38.\n",
            "  Batch 3,040  of  4,488.    Elapsed: 0:19:54.\n",
            "  Batch 3,080  of  4,488.    Elapsed: 0:20:09.\n",
            "  Batch 3,120  of  4,488.    Elapsed: 0:20:25.\n",
            "  Batch 3,160  of  4,488.    Elapsed: 0:20:41.\n",
            "  Batch 3,200  of  4,488.    Elapsed: 0:20:56.\n",
            "  Batch 3,240  of  4,488.    Elapsed: 0:21:12.\n",
            "  Batch 3,280  of  4,488.    Elapsed: 0:21:28.\n",
            "  Batch 3,320  of  4,488.    Elapsed: 0:21:43.\n",
            "  Batch 3,360  of  4,488.    Elapsed: 0:21:59.\n",
            "  Batch 3,400  of  4,488.    Elapsed: 0:22:15.\n",
            "  Batch 3,440  of  4,488.    Elapsed: 0:22:31.\n",
            "  Batch 3,480  of  4,488.    Elapsed: 0:22:46.\n",
            "  Batch 3,520  of  4,488.    Elapsed: 0:23:02.\n",
            "  Batch 3,560  of  4,488.    Elapsed: 0:23:18.\n",
            "  Batch 3,600  of  4,488.    Elapsed: 0:23:33.\n",
            "  Batch 3,640  of  4,488.    Elapsed: 0:23:49.\n",
            "  Batch 3,680  of  4,488.    Elapsed: 0:24:05.\n",
            "  Batch 3,720  of  4,488.    Elapsed: 0:24:21.\n",
            "  Batch 3,760  of  4,488.    Elapsed: 0:24:36.\n",
            "  Batch 3,800  of  4,488.    Elapsed: 0:24:52.\n",
            "  Batch 3,840  of  4,488.    Elapsed: 0:25:08.\n",
            "  Batch 3,880  of  4,488.    Elapsed: 0:25:23.\n",
            "  Batch 3,920  of  4,488.    Elapsed: 0:25:39.\n",
            "  Batch 3,960  of  4,488.    Elapsed: 0:25:55.\n",
            "  Batch 4,000  of  4,488.    Elapsed: 0:26:10.\n",
            "  Batch 4,040  of  4,488.    Elapsed: 0:26:26.\n",
            "  Batch 4,080  of  4,488.    Elapsed: 0:26:42.\n",
            "  Batch 4,120  of  4,488.    Elapsed: 0:26:57.\n",
            "  Batch 4,160  of  4,488.    Elapsed: 0:27:13.\n",
            "  Batch 4,200  of  4,488.    Elapsed: 0:27:29.\n",
            "  Batch 4,240  of  4,488.    Elapsed: 0:27:44.\n",
            "  Batch 4,280  of  4,488.    Elapsed: 0:28:00.\n",
            "  Batch 4,320  of  4,488.    Elapsed: 0:28:16.\n",
            "  Batch 4,360  of  4,488.    Elapsed: 0:28:32.\n",
            "  Batch 4,400  of  4,488.    Elapsed: 0:28:47.\n",
            "  Batch 4,440  of  4,488.    Elapsed: 0:29:03.\n",
            "  Batch 4,480  of  4,488.    Elapsed: 0:29:19.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:29:22\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation took: 0:01:03\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,488.    Elapsed: 0:00:16.\n",
            "  Batch    80  of  4,488.    Elapsed: 0:00:31.\n",
            "  Batch   120  of  4,488.    Elapsed: 0:00:47.\n",
            "  Batch   160  of  4,488.    Elapsed: 0:01:03.\n",
            "  Batch   200  of  4,488.    Elapsed: 0:01:18.\n",
            "  Batch   240  of  4,488.    Elapsed: 0:01:34.\n",
            "  Batch   280  of  4,488.    Elapsed: 0:01:50.\n",
            "  Batch   320  of  4,488.    Elapsed: 0:02:06.\n",
            "  Batch   360  of  4,488.    Elapsed: 0:02:21.\n",
            "  Batch   400  of  4,488.    Elapsed: 0:02:37.\n",
            "  Batch   440  of  4,488.    Elapsed: 0:02:53.\n",
            "  Batch   480  of  4,488.    Elapsed: 0:03:08.\n",
            "  Batch   520  of  4,488.    Elapsed: 0:03:24.\n",
            "  Batch   560  of  4,488.    Elapsed: 0:03:40.\n",
            "  Batch   600  of  4,488.    Elapsed: 0:03:55.\n",
            "  Batch   640  of  4,488.    Elapsed: 0:04:11.\n",
            "  Batch   680  of  4,488.    Elapsed: 0:04:27.\n",
            "  Batch   720  of  4,488.    Elapsed: 0:04:42.\n",
            "  Batch   760  of  4,488.    Elapsed: 0:04:58.\n",
            "  Batch   800  of  4,488.    Elapsed: 0:05:14.\n",
            "  Batch   840  of  4,488.    Elapsed: 0:05:29.\n",
            "  Batch   880  of  4,488.    Elapsed: 0:05:45.\n",
            "  Batch   920  of  4,488.    Elapsed: 0:06:01.\n",
            "  Batch   960  of  4,488.    Elapsed: 0:06:16.\n",
            "  Batch 1,000  of  4,488.    Elapsed: 0:06:32.\n",
            "  Batch 1,040  of  4,488.    Elapsed: 0:06:48.\n",
            "  Batch 1,080  of  4,488.    Elapsed: 0:07:04.\n",
            "  Batch 1,120  of  4,488.    Elapsed: 0:07:19.\n",
            "  Batch 1,160  of  4,488.    Elapsed: 0:07:35.\n",
            "  Batch 1,200  of  4,488.    Elapsed: 0:07:51.\n",
            "  Batch 1,240  of  4,488.    Elapsed: 0:08:06.\n",
            "  Batch 1,280  of  4,488.    Elapsed: 0:08:22.\n",
            "  Batch 1,320  of  4,488.    Elapsed: 0:08:38.\n",
            "  Batch 1,360  of  4,488.    Elapsed: 0:08:53.\n",
            "  Batch 1,400  of  4,488.    Elapsed: 0:09:09.\n",
            "  Batch 1,440  of  4,488.    Elapsed: 0:09:25.\n",
            "  Batch 1,480  of  4,488.    Elapsed: 0:09:40.\n",
            "  Batch 1,520  of  4,488.    Elapsed: 0:09:56.\n",
            "  Batch 1,560  of  4,488.    Elapsed: 0:10:11.\n",
            "  Batch 1,600  of  4,488.    Elapsed: 0:10:27.\n",
            "  Batch 1,640  of  4,488.    Elapsed: 0:10:43.\n",
            "  Batch 1,680  of  4,488.    Elapsed: 0:10:59.\n",
            "  Batch 1,720  of  4,488.    Elapsed: 0:11:14.\n",
            "  Batch 1,760  of  4,488.    Elapsed: 0:11:30.\n",
            "  Batch 1,800  of  4,488.    Elapsed: 0:11:45.\n",
            "  Batch 1,840  of  4,488.    Elapsed: 0:12:01.\n",
            "  Batch 1,880  of  4,488.    Elapsed: 0:12:17.\n",
            "  Batch 1,920  of  4,488.    Elapsed: 0:12:33.\n",
            "  Batch 1,960  of  4,488.    Elapsed: 0:12:48.\n",
            "  Batch 2,000  of  4,488.    Elapsed: 0:13:04.\n",
            "  Batch 2,040  of  4,488.    Elapsed: 0:13:20.\n",
            "  Batch 2,080  of  4,488.    Elapsed: 0:13:35.\n",
            "  Batch 2,120  of  4,488.    Elapsed: 0:13:51.\n",
            "  Batch 2,160  of  4,488.    Elapsed: 0:14:07.\n",
            "  Batch 2,200  of  4,488.    Elapsed: 0:14:22.\n",
            "  Batch 2,240  of  4,488.    Elapsed: 0:14:38.\n",
            "  Batch 2,280  of  4,488.    Elapsed: 0:14:54.\n",
            "  Batch 2,320  of  4,488.    Elapsed: 0:15:09.\n",
            "  Batch 2,360  of  4,488.    Elapsed: 0:15:25.\n",
            "  Batch 2,400  of  4,488.    Elapsed: 0:15:41.\n",
            "  Batch 2,440  of  4,488.    Elapsed: 0:15:56.\n",
            "  Batch 2,480  of  4,488.    Elapsed: 0:16:12.\n",
            "  Batch 2,520  of  4,488.    Elapsed: 0:16:28.\n",
            "  Batch 2,560  of  4,488.    Elapsed: 0:16:43.\n",
            "  Batch 2,600  of  4,488.    Elapsed: 0:16:59.\n",
            "  Batch 2,640  of  4,488.    Elapsed: 0:17:15.\n",
            "  Batch 2,680  of  4,488.    Elapsed: 0:17:30.\n",
            "  Batch 2,720  of  4,488.    Elapsed: 0:17:46.\n",
            "  Batch 2,760  of  4,488.    Elapsed: 0:18:01.\n",
            "  Batch 2,800  of  4,488.    Elapsed: 0:18:17.\n",
            "  Batch 2,840  of  4,488.    Elapsed: 0:18:33.\n",
            "  Batch 2,880  of  4,488.    Elapsed: 0:18:48.\n",
            "  Batch 2,920  of  4,488.    Elapsed: 0:19:04.\n",
            "  Batch 2,960  of  4,488.    Elapsed: 0:19:20.\n",
            "  Batch 3,000  of  4,488.    Elapsed: 0:19:35.\n",
            "  Batch 3,040  of  4,488.    Elapsed: 0:19:51.\n",
            "  Batch 3,080  of  4,488.    Elapsed: 0:20:07.\n",
            "  Batch 3,120  of  4,488.    Elapsed: 0:20:22.\n",
            "  Batch 3,160  of  4,488.    Elapsed: 0:20:38.\n",
            "  Batch 3,200  of  4,488.    Elapsed: 0:20:54.\n",
            "  Batch 3,240  of  4,488.    Elapsed: 0:21:09.\n",
            "  Batch 3,280  of  4,488.    Elapsed: 0:21:25.\n",
            "  Batch 3,320  of  4,488.    Elapsed: 0:21:41.\n",
            "  Batch 3,360  of  4,488.    Elapsed: 0:21:56.\n",
            "  Batch 3,400  of  4,488.    Elapsed: 0:22:12.\n",
            "  Batch 3,440  of  4,488.    Elapsed: 0:22:28.\n",
            "  Batch 3,480  of  4,488.    Elapsed: 0:22:44.\n",
            "  Batch 3,520  of  4,488.    Elapsed: 0:22:59.\n",
            "  Batch 3,560  of  4,488.    Elapsed: 0:23:15.\n",
            "  Batch 3,600  of  4,488.    Elapsed: 0:23:31.\n",
            "  Batch 3,640  of  4,488.    Elapsed: 0:23:46.\n",
            "  Batch 3,680  of  4,488.    Elapsed: 0:24:02.\n",
            "  Batch 3,720  of  4,488.    Elapsed: 0:24:18.\n",
            "  Batch 3,760  of  4,488.    Elapsed: 0:24:33.\n",
            "  Batch 3,800  of  4,488.    Elapsed: 0:24:49.\n",
            "  Batch 3,840  of  4,488.    Elapsed: 0:25:05.\n",
            "  Batch 3,880  of  4,488.    Elapsed: 0:25:20.\n",
            "  Batch 3,920  of  4,488.    Elapsed: 0:25:36.\n",
            "  Batch 3,960  of  4,488.    Elapsed: 0:25:52.\n",
            "  Batch 4,000  of  4,488.    Elapsed: 0:26:07.\n",
            "  Batch 4,040  of  4,488.    Elapsed: 0:26:23.\n",
            "  Batch 4,080  of  4,488.    Elapsed: 0:26:39.\n",
            "  Batch 4,120  of  4,488.    Elapsed: 0:26:54.\n",
            "  Batch 4,160  of  4,488.    Elapsed: 0:27:10.\n",
            "  Batch 4,200  of  4,488.    Elapsed: 0:27:26.\n",
            "  Batch 4,240  of  4,488.    Elapsed: 0:27:41.\n",
            "  Batch 4,280  of  4,488.    Elapsed: 0:27:57.\n",
            "  Batch 4,320  of  4,488.    Elapsed: 0:28:13.\n",
            "  Batch 4,360  of  4,488.    Elapsed: 0:28:28.\n",
            "  Batch 4,400  of  4,488.    Elapsed: 0:28:44.\n",
            "  Batch 4,440  of  4,488.    Elapsed: 0:29:00.\n",
            "  Batch 4,480  of  4,488.    Elapsed: 0:29:16.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:29:19\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation took: 0:01:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,488.    Elapsed: 0:00:16.\n",
            "  Batch    80  of  4,488.    Elapsed: 0:00:31.\n",
            "  Batch   120  of  4,488.    Elapsed: 0:00:47.\n",
            "  Batch   160  of  4,488.    Elapsed: 0:01:03.\n",
            "  Batch   200  of  4,488.    Elapsed: 0:01:19.\n",
            "  Batch   240  of  4,488.    Elapsed: 0:01:34.\n",
            "  Batch   280  of  4,488.    Elapsed: 0:01:50.\n",
            "  Batch   320  of  4,488.    Elapsed: 0:02:05.\n",
            "  Batch   360  of  4,488.    Elapsed: 0:02:21.\n",
            "  Batch   400  of  4,488.    Elapsed: 0:02:37.\n",
            "  Batch   440  of  4,488.    Elapsed: 0:02:52.\n",
            "  Batch   480  of  4,488.    Elapsed: 0:03:08.\n",
            "  Batch   520  of  4,488.    Elapsed: 0:03:23.\n",
            "  Batch   560  of  4,488.    Elapsed: 0:03:39.\n",
            "  Batch   600  of  4,488.    Elapsed: 0:03:55.\n",
            "  Batch   640  of  4,488.    Elapsed: 0:04:10.\n",
            "  Batch   680  of  4,488.    Elapsed: 0:04:26.\n",
            "  Batch   720  of  4,488.    Elapsed: 0:04:42.\n",
            "  Batch   760  of  4,488.    Elapsed: 0:04:57.\n",
            "  Batch   800  of  4,488.    Elapsed: 0:05:13.\n",
            "  Batch   840  of  4,488.    Elapsed: 0:05:29.\n",
            "  Batch   880  of  4,488.    Elapsed: 0:05:44.\n",
            "  Batch   920  of  4,488.    Elapsed: 0:06:00.\n",
            "  Batch   960  of  4,488.    Elapsed: 0:06:15.\n",
            "  Batch 1,000  of  4,488.    Elapsed: 0:06:31.\n",
            "  Batch 1,040  of  4,488.    Elapsed: 0:06:47.\n",
            "  Batch 1,080  of  4,488.    Elapsed: 0:07:02.\n",
            "  Batch 1,120  of  4,488.    Elapsed: 0:07:18.\n",
            "  Batch 1,160  of  4,488.    Elapsed: 0:07:34.\n",
            "  Batch 1,200  of  4,488.    Elapsed: 0:07:49.\n",
            "  Batch 1,240  of  4,488.    Elapsed: 0:08:05.\n",
            "  Batch 1,280  of  4,488.    Elapsed: 0:08:20.\n",
            "  Batch 1,320  of  4,488.    Elapsed: 0:08:36.\n",
            "  Batch 1,360  of  4,488.    Elapsed: 0:08:52.\n",
            "  Batch 1,400  of  4,488.    Elapsed: 0:09:07.\n",
            "  Batch 1,440  of  4,488.    Elapsed: 0:09:23.\n",
            "  Batch 1,480  of  4,488.    Elapsed: 0:09:38.\n",
            "  Batch 1,520  of  4,488.    Elapsed: 0:09:54.\n",
            "  Batch 1,560  of  4,488.    Elapsed: 0:10:10.\n",
            "  Batch 1,600  of  4,488.    Elapsed: 0:10:25.\n",
            "  Batch 1,640  of  4,488.    Elapsed: 0:10:41.\n",
            "  Batch 1,680  of  4,488.    Elapsed: 0:10:57.\n",
            "  Batch 1,720  of  4,488.    Elapsed: 0:11:12.\n",
            "  Batch 1,760  of  4,488.    Elapsed: 0:11:28.\n",
            "  Batch 1,800  of  4,488.    Elapsed: 0:11:43.\n",
            "  Batch 1,840  of  4,488.    Elapsed: 0:11:59.\n",
            "  Batch 1,880  of  4,488.    Elapsed: 0:12:15.\n",
            "  Batch 1,920  of  4,488.    Elapsed: 0:12:30.\n",
            "  Batch 1,960  of  4,488.    Elapsed: 0:12:46.\n",
            "  Batch 2,000  of  4,488.    Elapsed: 0:13:01.\n",
            "  Batch 2,040  of  4,488.    Elapsed: 0:13:17.\n",
            "  Batch 2,080  of  4,488.    Elapsed: 0:13:33.\n",
            "  Batch 2,120  of  4,488.    Elapsed: 0:13:48.\n",
            "  Batch 2,160  of  4,488.    Elapsed: 0:14:04.\n",
            "  Batch 2,200  of  4,488.    Elapsed: 0:14:19.\n",
            "  Batch 2,240  of  4,488.    Elapsed: 0:14:35.\n",
            "  Batch 2,280  of  4,488.    Elapsed: 0:14:51.\n",
            "  Batch 2,320  of  4,488.    Elapsed: 0:15:06.\n",
            "  Batch 2,360  of  4,488.    Elapsed: 0:15:22.\n",
            "  Batch 2,400  of  4,488.    Elapsed: 0:15:37.\n",
            "  Batch 2,440  of  4,488.    Elapsed: 0:15:53.\n",
            "  Batch 2,480  of  4,488.    Elapsed: 0:16:09.\n",
            "  Batch 2,520  of  4,488.    Elapsed: 0:16:24.\n",
            "  Batch 2,560  of  4,488.    Elapsed: 0:16:40.\n",
            "  Batch 2,600  of  4,488.    Elapsed: 0:16:55.\n",
            "  Batch 2,640  of  4,488.    Elapsed: 0:17:11.\n",
            "  Batch 2,680  of  4,488.    Elapsed: 0:17:26.\n",
            "  Batch 2,720  of  4,488.    Elapsed: 0:17:42.\n",
            "  Batch 2,760  of  4,488.    Elapsed: 0:17:58.\n",
            "  Batch 2,800  of  4,488.    Elapsed: 0:18:13.\n",
            "  Batch 2,840  of  4,488.    Elapsed: 0:18:29.\n",
            "  Batch 2,880  of  4,488.    Elapsed: 0:18:44.\n",
            "  Batch 2,920  of  4,488.    Elapsed: 0:19:00.\n",
            "  Batch 2,960  of  4,488.    Elapsed: 0:19:16.\n",
            "  Batch 3,000  of  4,488.    Elapsed: 0:19:31.\n",
            "  Batch 3,040  of  4,488.    Elapsed: 0:19:47.\n",
            "  Batch 3,080  of  4,488.    Elapsed: 0:20:03.\n",
            "  Batch 3,120  of  4,488.    Elapsed: 0:20:18.\n",
            "  Batch 3,160  of  4,488.    Elapsed: 0:20:34.\n",
            "  Batch 3,200  of  4,488.    Elapsed: 0:20:49.\n",
            "  Batch 3,240  of  4,488.    Elapsed: 0:21:05.\n",
            "  Batch 3,280  of  4,488.    Elapsed: 0:21:21.\n",
            "  Batch 3,320  of  4,488.    Elapsed: 0:21:36.\n",
            "  Batch 3,360  of  4,488.    Elapsed: 0:21:52.\n",
            "  Batch 3,400  of  4,488.    Elapsed: 0:22:07.\n",
            "  Batch 3,440  of  4,488.    Elapsed: 0:22:23.\n",
            "  Batch 3,480  of  4,488.    Elapsed: 0:22:39.\n",
            "  Batch 3,520  of  4,488.    Elapsed: 0:22:54.\n",
            "  Batch 3,560  of  4,488.    Elapsed: 0:23:10.\n",
            "  Batch 3,600  of  4,488.    Elapsed: 0:23:26.\n",
            "  Batch 3,640  of  4,488.    Elapsed: 0:23:41.\n",
            "  Batch 3,680  of  4,488.    Elapsed: 0:23:57.\n",
            "  Batch 3,720  of  4,488.    Elapsed: 0:24:13.\n",
            "  Batch 3,760  of  4,488.    Elapsed: 0:24:28.\n",
            "  Batch 3,800  of  4,488.    Elapsed: 0:24:44.\n",
            "  Batch 3,840  of  4,488.    Elapsed: 0:24:59.\n",
            "  Batch 3,880  of  4,488.    Elapsed: 0:25:15.\n",
            "  Batch 3,920  of  4,488.    Elapsed: 0:25:31.\n",
            "  Batch 3,960  of  4,488.    Elapsed: 0:25:46.\n",
            "  Batch 4,000  of  4,488.    Elapsed: 0:26:02.\n",
            "  Batch 4,040  of  4,488.    Elapsed: 0:26:18.\n",
            "  Batch 4,080  of  4,488.    Elapsed: 0:26:33.\n",
            "  Batch 4,120  of  4,488.    Elapsed: 0:26:49.\n",
            "  Batch 4,160  of  4,488.    Elapsed: 0:27:05.\n",
            "  Batch 4,200  of  4,488.    Elapsed: 0:27:20.\n",
            "  Batch 4,240  of  4,488.    Elapsed: 0:27:36.\n",
            "  Batch 4,280  of  4,488.    Elapsed: 0:27:52.\n",
            "  Batch 4,320  of  4,488.    Elapsed: 0:28:07.\n",
            "  Batch 4,360  of  4,488.    Elapsed: 0:28:23.\n",
            "  Batch 4,400  of  4,488.    Elapsed: 0:28:39.\n",
            "  Batch 4,440  of  4,488.    Elapsed: 0:28:54.\n",
            "  Batch 4,480  of  4,488.    Elapsed: 0:29:10.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:29:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation took: 0:01:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,488.    Elapsed: 0:00:16.\n",
            "  Batch    80  of  4,488.    Elapsed: 0:00:31.\n",
            "  Batch   120  of  4,488.    Elapsed: 0:00:47.\n",
            "  Batch   160  of  4,488.    Elapsed: 0:01:02.\n",
            "  Batch   200  of  4,488.    Elapsed: 0:01:18.\n",
            "  Batch   240  of  4,488.    Elapsed: 0:01:34.\n",
            "  Batch   280  of  4,488.    Elapsed: 0:01:49.\n",
            "  Batch   320  of  4,488.    Elapsed: 0:02:05.\n",
            "  Batch   360  of  4,488.    Elapsed: 0:02:20.\n",
            "  Batch   400  of  4,488.    Elapsed: 0:02:36.\n",
            "  Batch   440  of  4,488.    Elapsed: 0:02:51.\n",
            "  Batch   480  of  4,488.    Elapsed: 0:03:07.\n",
            "  Batch   520  of  4,488.    Elapsed: 0:03:23.\n",
            "  Batch   560  of  4,488.    Elapsed: 0:03:38.\n",
            "  Batch   600  of  4,488.    Elapsed: 0:03:54.\n",
            "  Batch   640  of  4,488.    Elapsed: 0:04:09.\n",
            "  Batch   680  of  4,488.    Elapsed: 0:04:25.\n",
            "  Batch   720  of  4,488.    Elapsed: 0:04:41.\n",
            "  Batch   760  of  4,488.    Elapsed: 0:04:56.\n",
            "  Batch   800  of  4,488.    Elapsed: 0:05:12.\n",
            "  Batch   840  of  4,488.    Elapsed: 0:05:27.\n",
            "  Batch   880  of  4,488.    Elapsed: 0:05:43.\n",
            "  Batch   920  of  4,488.    Elapsed: 0:05:58.\n",
            "  Batch   960  of  4,488.    Elapsed: 0:06:14.\n",
            "  Batch 1,000  of  4,488.    Elapsed: 0:06:30.\n",
            "  Batch 1,040  of  4,488.    Elapsed: 0:06:45.\n",
            "  Batch 1,080  of  4,488.    Elapsed: 0:07:01.\n",
            "  Batch 1,120  of  4,488.    Elapsed: 0:07:16.\n",
            "  Batch 1,160  of  4,488.    Elapsed: 0:07:32.\n",
            "  Batch 1,200  of  4,488.    Elapsed: 0:07:48.\n",
            "  Batch 1,240  of  4,488.    Elapsed: 0:08:03.\n",
            "  Batch 1,280  of  4,488.    Elapsed: 0:08:19.\n",
            "  Batch 1,320  of  4,488.    Elapsed: 0:08:34.\n",
            "  Batch 1,360  of  4,488.    Elapsed: 0:08:50.\n",
            "  Batch 1,400  of  4,488.    Elapsed: 0:09:06.\n",
            "  Batch 1,440  of  4,488.    Elapsed: 0:09:21.\n",
            "  Batch 1,480  of  4,488.    Elapsed: 0:09:37.\n",
            "  Batch 1,520  of  4,488.    Elapsed: 0:09:52.\n",
            "  Batch 1,560  of  4,488.    Elapsed: 0:10:08.\n",
            "  Batch 1,600  of  4,488.    Elapsed: 0:10:24.\n",
            "  Batch 1,640  of  4,488.    Elapsed: 0:10:39.\n",
            "  Batch 1,680  of  4,488.    Elapsed: 0:10:55.\n",
            "  Batch 1,720  of  4,488.    Elapsed: 0:11:10.\n",
            "  Batch 1,760  of  4,488.    Elapsed: 0:11:26.\n",
            "  Batch 1,800  of  4,488.    Elapsed: 0:11:42.\n",
            "  Batch 1,840  of  4,488.    Elapsed: 0:11:57.\n",
            "  Batch 1,880  of  4,488.    Elapsed: 0:12:13.\n",
            "  Batch 1,920  of  4,488.    Elapsed: 0:12:28.\n",
            "  Batch 1,960  of  4,488.    Elapsed: 0:12:44.\n",
            "  Batch 2,000  of  4,488.    Elapsed: 0:13:00.\n",
            "  Batch 2,040  of  4,488.    Elapsed: 0:13:15.\n",
            "  Batch 2,080  of  4,488.    Elapsed: 0:13:31.\n",
            "  Batch 2,120  of  4,488.    Elapsed: 0:13:46.\n",
            "  Batch 2,160  of  4,488.    Elapsed: 0:14:02.\n",
            "  Batch 2,200  of  4,488.    Elapsed: 0:14:18.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwH2XgWRkFBd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}